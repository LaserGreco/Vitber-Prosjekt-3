{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction and noise removal of face images with Non-Negative Matrix Factorization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduksjon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Required to import cv2 !!!\n",
    "# %pip install opencv-python\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "def bmatrix(a):\n",
    "    \"\"\"Returns a LaTeX bmatrix\n",
    "\n",
    "    :a: numpy array\n",
    "    :returns: LaTeX bmatrix as a string\n",
    "    \"\"\"\n",
    "    if len(a.shape) > 2:\n",
    "        raise ValueError('bmatrix can at most display two dimensions')\n",
    "    lines = str(a).replace('[', '').replace(']', '').splitlines()\n",
    "    rv = [r'\\begin{bmatrix}']\n",
    "    rv += ['  ' + ' & '.join(l.split()) + r'\\\\' for l in lines]\n",
    "    rv +=  [r'\\end{bmatrix}']\n",
    "    return '\\n'.join(rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMF(V, d, delta = 1e-9, maxiter = 1000, seed = 0):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        V: (m,n) input array\n",
    "        d: integer, Number of components we want to decompose V into\n",
    "        delta, float, small number for safe division\n",
    "        maxiter: integer, maximum number of iterations\n",
    "        seed: integer, random seed\n",
    "    output:\n",
    "        W: (m,d) array\n",
    "        H: (d,n) array\n",
    "    \"\"\"\n",
    "    m, n = np.shape(V)\n",
    "\n",
    "    if seed != 0:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    W0 = np.random.uniform(low=1e-20, high=1, size=m*d)\n",
    "    H0 = np.random.uniform(low=1e-20, high=1, size=n*d)\n",
    "    \n",
    "    W0 *= np.sqrt(np.mean(V)/d)\n",
    "    H0 *= np.sqrt(np.mean(V)/d)\n",
    "    \n",
    "    W0 = np.reshape(W0, (m, d))\n",
    "    H0 = np.reshape(H0, (d, n))\n",
    "    \n",
    "    H_k = H0\n",
    "    W_k = W0\n",
    "    diff = np.zeros(maxiter)\n",
    "    \n",
    "    for k in range(maxiter):\n",
    "        H_k = H_k*(np.dot(W_k.T, V))/(np.dot(np.dot(W_k.T, W_k), H_k)+ delta)\n",
    "        W_k = W_k*(np.dot(V, H_k.T))/(np.dot(np.dot(W_k, H_k), H_k.T)+ delta)\n",
    "        diff[k] = np.linalg.norm(V - np.dot(W_k, H_k))\n",
    "    \n",
    "    return W_k, H_k, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = np.array([\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "])\n",
    "\n",
    "A2 = np.array([\n",
    "    [1, 2],\n",
    "    [1, 1],\n",
    "    [1, 2]\n",
    "])\n",
    "\n",
    "A3 = np.array([\n",
    "    [2, 1, 1],\n",
    "    [2, 1, 1],\n",
    "    [1, 1, 2]\n",
    "])\n",
    "\n",
    "A4 = np.array([\n",
    "    [2, 1, 0],\n",
    "    [1, 2, 3],\n",
    "    [0, 3, 3]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-negative Matrix Factorization (NMF) is a technique used to represent a matrix A, but with a lower amount of data. The NMF-representation consists of two non-negative matrices W and H, where the dot product between W and H gives an approximation to the original matrix. In general if A is a m x n matrix, the NMF-algorithm will return the matrices W and H, with respectively dimensions m x d and d x n. Combined, W and H has fewer components than A, and as a result occupies less storage or memory. \n",
    "\n",
    "Later we will be testing the algorithm for different values of d, and investigate how this affects the the approximation. Before this we will prove and show a couple of NMF's properties.\n",
    "\n",
    "Firstly, lets prove that if the initial values of $W_0$ and $H_0$ are positive only gives non-negative updated values, when assuming that the input matrix A is non-negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Induction</b>\n",
    "1. \n",
    "    $W_0$ and $H_0$ are initialzed as positive, and A is assumed to be non-negative. \\\n",
    "    $\\Rightarrow$ $W_0$ and $H_0$ are non-negative.\n",
    "2. \n",
    "    Assume $W_k$ and $H_k$ are non-negative.\n",
    "3. \n",
    "    Updates are given by:\n",
    "    \\begin{aligned}\n",
    "        (H_{k+1})_{ij} \\leftarrow & (H_k)_{ij} \\cdot \\frac{(W^T_k A)_{ij}}{(W^T_k W_k H_K)_{ij}} \\\\\n",
    "        (W_{k+1})_{ij} \\leftarrow & (W_k)_{ij} \\cdot \\frac{(A H^T_{k+1})_{ij}}{(W_k H_{k+1} H_{k+1}^T)_{ij}}\n",
    "    \\end{aligned}\n",
    "    Since the matrix product of two non-negative matricies is also non-negative, every matrix product in the updates are non-negative, assuming that every factor is non-negative. \\\n",
    "    For $(H_{k+1})_{ij}$ every factor in every matrix product is assumed to be non-negative. Meaning the final product is something non-negative and non-negative. Meaning that $(H_{k+1})_{ij}$ must be non-negative. \\\n",
    "    The same logic works for $(W_{k+1})_{ij}$, since we now know that $(H_{k+1})_{ij}$ is also non-negative.\n",
    "\n",
    "Therefore all iterates $W_{k}$ and $H_{k}$ are non-negative, by induction $\\Box$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lets prove that $H_k$ is fixed when $(W_k^T A) \\oslash (W_k^T W_k H_k)=J_{m,n}$ is a matrix of ones.\n",
    "\n",
    "Let $(W_k^T A) \\oslash (W_k^T W_k H_k)=J_{m,n}$ be a matrix of ones.\n",
    "\\begin{aligned}\n",
    "    & H_{k+1} \\leftarrow H_k \\odot (W^T_k A) \\oslash (W^T_k W_k H_k) \\\\\n",
    "    \\Rightarrow & H_{k+1} \\leftarrow H_k \\odot J_{m,n} \\\\\n",
    "    \\Rightarrow &\\underline{H_{k+1} \\leftarrow H_k} \\\\\n",
    "\\end{aligned}\n",
    "Therefore if $(W_k^T A) \\oslash (W_k^T W_k H_k)=J_{m,n}$ is a matrix of ones, then $H_{k+1}=H_K$ and $H_k$ is a fixed point $\\Box$.\n",
    "\n",
    "Then lets show that this occures when $W_k H_k = A$.\n",
    "\n",
    "Let $W_k H_k = A$.\n",
    "\\begin{aligned}\n",
    "    (W_k^T A) \\oslash (W_k^T W_k H_k) = (W_k^T A) \\oslash (W_k^T A) = J_{m,n} \\\\\n",
    "\\end{aligned}\n",
    "Therefore if $W_k H_k = A$, $(W_k^T A) \\oslash (W_k^T W_k H_k)=J_{m,n}$ is a matrix of ones.\n",
    "\n",
    "Combing these two facts shows that if the algorithm has converged (i.e. $W_k H_k = A$), it will not update the the matrices, and therefore will not begin to diverge after converging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will show that we it is problematic to set the initial $W_0$ and $H_0$ to be matrices only containg zeros.\n",
    "\n",
    "Let $W_0=0_{m,d}$ and $H_0=0_{d,n}$.\n",
    "\\begin{aligned}\n",
    "    & H_{1} \\leftarrow H_0 \\odot (W^T_0 A) \\oslash (W^T_0 W_0 H_0) \\\\\n",
    "    \\Rightarrow & H_{1} \\leftarrow 0_{d,n} \\odot (0_{d,m} A) \\oslash (0_{d,m} 0_{m,d} 0_{d,n}) \\\\\n",
    "    \\Rightarrow & H_{1} \\leftarrow 0_{d,n} \\odot (0_{d,n}) \\oslash (0_{d,n}) \\\\\n",
    "\\end{aligned}\n",
    "This leads to being needed to calculate $0/0$, which is undefined. This is clearly problematic, and should be avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math\n",
    "\n",
    "def print_matrix(array):\n",
    "    data = ''\n",
    "    for line in array:        \n",
    "        if len(line) == 1:\n",
    "            data += ' %.3f &'%line + r' \\\\\\n'\n",
    "            continue\n",
    "        for element in line:\n",
    "            data += ' %.3f &'%element\n",
    "        data += r' \\\\' + '\\n'\n",
    "    display(Math('\\\\begin{bmatrix} \\n%s\\end{bmatrix}'%data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"d={1}\\n\")\n",
    "\n",
    "W_A11, H_A11, diff = NMF(A1, 1, seed=1)\n",
    "WH11 = np.dot(W_A11, H_A11)\n",
    "diff_A11 = np.linalg.norm(A1 - WH11)\n",
    "print(f\"||A_1-WH||={diff_A11:.3e}, seed=1\")\n",
    "\n",
    "W_A12, H_A12, diff = NMF(A1, 1, seed=2)\n",
    "WH12 = np.dot(W_A12, H_A12)\n",
    "diff_A12 = np.linalg.norm(A1 - WH12)\n",
    "print(f\"||A_1-WH||={diff_A12:.3e}, seed=2\")\n",
    "\n",
    "W_A21, H_A21 , diff = NMF(A2, 1, seed =1)\n",
    "WH21 = np.dot(W_A21, H_A21)\n",
    "diff_A21 = np.linalg.norm(A2 - WH21)\n",
    "print(f\"||A_2-WH||={diff_A21:.3e}, seed=1\")\n",
    "\n",
    "W_A22, H_A22 , diff = NMF(A2, 1, seed =2)\n",
    "WH22 = np.dot(W_A22, H_A22)\n",
    "diff_A22 = np.linalg.norm(A2 - WH22)\n",
    "print(f\"||A_2-WH||={diff_A22:.3e}, seed=2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With one itteration of NMF on the following matrices, we get:\n",
    "\n",
    "\n",
    "Initial Matrix| Seed | W | H | WH | $$||A-WH||_F$$\n",
    ":-------------------:|:---:|:---------------:|:---------------:|:---------------:|------------------------:\n",
    "**A1**       |$1$| \\begin{bmatrix}\n",
    "                        0.295\\\\\n",
    "                        0.509\n",
    "                        \\end{bmatrix}   | \\begin{bmatrix}\n",
    "                                                0.851 &\n",
    "                                                1.470\n",
    "                                            \\end{bmatrix}  |\\begin{bmatrix}\n",
    "                                                                0.251 & 0.434\\\\\n",
    "                                                                0.434 & 0.749\n",
    "                                                                \\end{bmatrix}|$1.000$\n",
    "**A1**       |$2$|\\begin{bmatrix}\n",
    "                        0.308\\\\\n",
    "                        0.018\n",
    "                        \\end{bmatrix}|\\begin{bmatrix}\n",
    "                                        3.232 &\n",
    "                                        0.192\n",
    "                                       \\end{bmatrix}|\\begin{bmatrix}\n",
    "                                                        0.996 & 0.059\\\\\n",
    "                                                        0.059 & 0.004\n",
    "                                                        \\end{bmatrix}|$1.000$\n",
    "**A2**       |$1$|\\begin{bmatrix}\n",
    "                        0.722\\\\\n",
    "                        0.441\\\\\n",
    "                        0.722\n",
    "                        \\end{bmatrix}|\\begin{bmatrix}\n",
    "                                        1.524 &\n",
    "                                        2.691\n",
    "                                        \\end{bmatrix}|\\begin{bmatrix}\n",
    "                                                           1.100 & 1.943\\\\\n",
    "                                                           0.671 & 1.186\\\\\n",
    "                                                           1.100 & 1.943\n",
    "                                                            \\end{bmatrix}|$0.411$\n",
    "**A2**       |$2$|\\begin{bmatrix}\n",
    "                        0.457\\\\\n",
    "                        0.279\\\\\n",
    "                        0.457\n",
    "                        \\end{bmatrix}|\\begin{bmatrix}\n",
    "                                        2.405 &\n",
    "                                        4.248\n",
    "                                        \\end{bmatrix}|\\begin{bmatrix}\n",
    "                                                        1.100 & 1.943 \\\\\n",
    "                                                        0.671 & 1.186 \\\\\n",
    "                                                        1.100 & 1.943\n",
    "                                                        \\end{bmatrix}|$0.411$\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compare W, H, WH and $\\lVert A-WH \\rVert_F$ after one iteration of NMF, there is only one quantity that is the same every time. That quantity is the $\\lVert A-WH \\rVert_F$, which becomes 1 with A1 as the initial grid, and 0.4112 with A2 as the initial grid. \n",
    "\n",
    "$\\lVert A-WH \\rVert_F$ is the square root of this sum of the absolute squares of the difference of the elements of the matrix. The other quantities: W, H and WH is not unique, but that is not expected since the NMF of a matrix is a non-unique approximation. Due to the non-unique approximation, there will usually be infinitely solutions to W and H, and furthermore WH. One interesting thing to take a closer look at is the matrix WH from A2, this matrix is exactly the same no matter what W and H are. because??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"d={2}\\n\")\n",
    "\n",
    "W_A11, H_A11, diff = NMF(A1, 2, seed=1)\n",
    "WH11 = np.dot(W_A11, H_A11)\n",
    "diff_A11 = np.linalg.norm(A1 - WH11)\n",
    "print(f\"||A_1-WH||={diff_A11:.3e}, seed=1\")\n",
    "\n",
    "W_A12, H_A12, diff = NMF(A1, 2, seed=2)\n",
    "WH12 = np.dot(W_A12, H_A12)\n",
    "diff_A12 = np.linalg.norm(A1 - WH12)\n",
    "print(f\"||A_1-WH||={diff_A12:.3e}, seed=2\")\n",
    "\n",
    "W_A21, H_A21 , diff = NMF(A2, 2, seed =1)\n",
    "WH21 = np.dot(W_A21, H_A21)\n",
    "diff_A21 = np.linalg.norm(A2 - WH21)\n",
    "print(f\"||A_2-WH||={diff_A21:.3e}, seed=1\")\n",
    "\n",
    "W_A22, H_A22 , diff = NMF(A2, 2, seed =2)\n",
    "WH22 = np.dot(W_A22, H_A22)\n",
    "diff_A22 = np.linalg.norm(A2 - WH22)\n",
    "print(f\"||A_2-WH||={diff_A22:.3e}, seed=2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Matrix| Seed | W | H | WH | $$||A-WH||_F$$\n",
    ":-------------------:|:---:|:---------------:|:---------------:|:---------------:|------------------------:\n",
    "**A1**       |$1$|\\begin{bmatrix}\n",
    "                  0.380 & 0.\\\\\n",
    "                  0. & 0.456\\\\\n",
    "                \\end{bmatrix}   |   \\begin{bmatrix}\n",
    "                                      2.632 & 0.\\\\\n",
    "                                      0. & 2.193\\\\\n",
    "                                    \\end{bmatrix}  |\\begin{bmatrix}\n",
    "                                                      1. & 0.\\\\\n",
    "                                                      0. & 1.\\\\\n",
    "                                                    \\end{bmatrix}|$5.936 \\cdot 10^{-10}$\n",
    "**A1**       |$2$|\\begin{bmatrix}\n",
    "                  0.472 & 0.\\\\\n",
    "                  0. & 0.291\\\\\n",
    "                \\end{bmatrix}|  \\begin{bmatrix}\n",
    "                                  2.117 & 0.\\\\\n",
    "                                  0. & 3.441\\\\\n",
    "                                \\end{bmatrix}|  \\begin{bmatrix}\n",
    "                                                  1. & 0.\\\\\n",
    "                                                  0. & 1.\\\\\n",
    "                                                \\end{bmatrix}|$5.546 \\cdot 10^{-10}$\n",
    "**A2**       |$1$|\\begin{bmatrix}\n",
    "                  0.453 & 0.363\\\\\n",
    "                  0. & 0.435\\\\\n",
    "                  0.453 & 0.363\\\\\n",
    "                \\end{bmatrix}|  \\begin{bmatrix}\n",
    "                                  0.365 & 2.573\\\\\n",
    "                                  2.300 & 2.300\\\\\n",
    "                                \\end{bmatrix}|  \\begin{bmatrix}\n",
    "                                                  1. & 2.\\\\\n",
    "                                                  1. & 1.\\\\\n",
    "                                                  1. & 2.\\\\\n",
    "                                                \\end{bmatrix}|$7.718 \\cdot 10^{-10}$\n",
    "**A2**       |$2$|\\begin{bmatrix}\n",
    "                  0.566 & 0.098\\\\\n",
    "                  0.164 & 0.442\\\\\n",
    "                  0.566 & 0.0976\\\\\n",
    "                \\end{bmatrix}|  \\begin{bmatrix}\n",
    "                                  1.470 & 3.357\\\\\n",
    "                                  1.715 & 1.014\\\\\n",
    "                                \\end{bmatrix}|  \\begin{bmatrix}\n",
    "                                                  1. & 2.\\\\\n",
    "                                                  1. & 1.\\\\\n",
    "                                                  1. & 2.\\\\\n",
    "                                                \\end{bmatrix}|$9.605 \\cdot 10^{-10}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lVert A-WH \\rVert$ for A1 and A2 with $d=2$ is in the range $1^{-9}$ to $1^{-10}$, which is very close to zero. In this instance $d$ is big enough to not lose any information during the NMF, since A1 is a $2x2$ matrix, and A2 is a $2x3$ matrix. As a result of the NMF we have then just increased the amount of data stored, which is the exact opposite of what we want to accomplish using the NMF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f) og g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rank of a matrix is defined as the maximum number of linearly independent column vectors in the matrix. It is possible to find the number of linearly independent column vectors by Gauss eliminating the matrix. A3 can be eliminated down to the matrix:\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & -1\\\\\n",
    "0 & 1 & 3 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "This Matrix consist of 2 linearly independent column vectors, and has Rank=2. The same process can be done to A4, but nummerically there is a easier way to figure out the rank of a matrix, by the function numpy.linalg.matrix_rank(). This function just takes in the matrix and gives out the rank directly. As is done below, and we concludes that A3 has rank=2 and A4 has rank=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"A3 rank: {np.linalg.matrix_rank(A3)}\\nA4 rank: {np.linalg.matrix_rank(A4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the rank of the matrix is the maximum number of linearly independent columnvectors, all the other columnvectors can be described using the ones we know. $d$ is the number of columns in our factorized vector W. Therefore it is not farfetched to believe there is some sort of connection between the rank and the optimal choice of $d$. Given that we now know the rank of the matrices, we want to investigate this further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "for d in range(1, 4):\n",
    "    W, H, diff = NMF(A3, d)\n",
    "    ax1.semilogy(diff, label=f\"d={d}\")\n",
    "\n",
    "ax1.set_title(\"A3\", size=14)\n",
    "ax1.set_ylabel(r'$\\Vert A - W_kH_k \\vert_{F}$', size=12)\n",
    "ax1.set_xlabel(\"k\", size=12)\n",
    "ax1.legend()\n",
    "    \n",
    "for d in range(1, 4):\n",
    "    W, H, diff = NMF(A4, d)\n",
    "    ax2.semilogy(diff, label=f\"d={d}\")\n",
    "\n",
    "    \n",
    "ax2.set_title(\"A4\", size=14)\n",
    "ax2.set_ylabel(r'$\\Vert A - W_kH_k \\vert_{F}$', size=12)\n",
    "ax2.set_xlabel(\"k\", size=12)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plots indicates there is a connection between the rank and the best d. The Frobenius norm that reaches the lowest value for each of the initial matrices is the one with d equal to the rank. For A3 both $d=2$ and $d=3$ converges to approximately the same value, but $d=3$ is unstable and varies each time. For A4 $d=3$ converges to a value way lower than both $d=1,2$. One thing to note for all of the plots $\\lVert A-WH \\rVert$ satisfies $\\lVert A-W_{k+1}H_{k+1} \\rVert \\leq \\lVert A-W_{k}H_{k} \\rVert$, but this only implies that it finds a local minimizer, and the convergens can for some initial conditions be very slow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduksjon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that NMF is both defined and implemented, it is interersting to investigate it's properties. Therefore there is a need of a large dataset to apply NMF to. The dataset which will be used is 10 000 Cryptopunks NFTs. A Cryptopunk is a digital 24 x 24 RGBA image. Every Cryptopunk is algorithmically generated, meaning certain features such as cigarettes and hairstyles are shared between images. This means that the images should be more or less able to be decomposed into image components, so that every image can be described as a sum of image components. To verify this claim we are going to make us of the NMF-algorithm to approximate such a components and decompisitions.\n",
    "\n",
    "Now we need to represent the data in such a way that it is possible to apply the NMF-algorithm. Firstly we randomly select N Cryptopunks from the pool of 10 000. This gives 500 24 x 24 RGBA images. A natural way to store the images is to store them in a 24 x 24 x 4 x N array, i.e. 24 rows x 24 columns x 4 color channels x N images. Below is a function which loads 500 randomly picked images from the dataset a stores them in an array as described. One thing to note is that the RGBA-values are divided by 255.0. This is to create a array of floats, with values from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(N):\n",
    "    \"\"\"\n",
    "    Loads images from cryptopunk dataset. The loading order is deterministic,\n",
    "    so for a certain N the exact same images will be loaded. \n",
    "    Input:\n",
    "        N, integer, number of images to load\n",
    "    Output:\n",
    "        faces, (24,24,4,N) numpy array containing images\n",
    "    \"\"\"\n",
    "\n",
    "    # Allocate array to store images\n",
    "    faces = np.zeros((24,24,4,N))\n",
    "\n",
    "    # Iteration variable\n",
    "    i = 0\n",
    "\n",
    "    # Iterate over folders\n",
    "    for subdir, dirs, files in os.walk('./imgs'):\n",
    "\n",
    "        # Iterate over files\n",
    "        for file in files:\n",
    "\n",
    "            # Filepath to load from\n",
    "            filepath = subdir + os.sep + file\n",
    "\n",
    "            # Make sure that the file is a .png\n",
    "            if filepath[-3:] == 'png':\n",
    "\n",
    "                # Load the image\n",
    "                im = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "                # Convert it to RGBA and rescale pixels\n",
    "                faces[:,:,:,i] = cv2.cvtColor(im, cv2.COLOR_BGRA2RGBA)/255.0\n",
    "\n",
    "                i+=1\n",
    "            if i == N:\n",
    "                break\n",
    "                \n",
    "    return faces\n",
    "\n",
    "# Number of faces to keep in final array\n",
    "N = 500\n",
    "\n",
    "# Load all 10000 images\n",
    "faces = load_images(10000)\n",
    "\n",
    "# Select N random images\n",
    "choices = np.random.choice(faces.shape[-1],N, replace = False)\n",
    "faces = faces[:,:,:,choices]\n",
    "\n",
    "# Check that the shape is correct\n",
    "print(faces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the images now being loaded into the kernel it is now possible to plot and view some of the images picked. Below is a function which plots the first $nplot^2$ images in the input array in a square grid. After the implementation a 8 x 8 grid of the images loaded in the kernel are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting images\n",
    "def plotimgs(imgs, nplot = 8, rescale = False, filename = None):\n",
    "    \"\"\"\n",
    "    Plots nplot*nplot images on an nplot x nplot grid. \n",
    "    Saves to given filename if filename is given\n",
    "    Can also rescale the RGB channels\n",
    "    input:\n",
    "        imgs: (24,24,4,N) or (24,24,3,N) array containing images, where N > nplot**2\n",
    "        nplot: integer, nplot**2 images will be plotted\n",
    "        rescale: bool\n",
    "        filename: string, figure will be saved to this location. Should end with \".png\".\n",
    "    \"\"\"\n",
    "    # We will change some of the parameters of matplotlib, so we store the initial ones\n",
    "    oldparams = plt.rcParams['figure.figsize']\n",
    "\n",
    "    # New params to make better plot. There definitely exists better ways of doing this\n",
    "    plt.rcParams['figure.figsize'] = (16, 16)\n",
    "\n",
    "    # Initialize subplots\n",
    "    fig, axes = plt.subplots(nplot,nplot)\n",
    "\n",
    "    # Set background color\n",
    "    plt.gcf().set_facecolor(\"lightgray\")\n",
    "\n",
    "    # Iterate over images\n",
    "    for idx in range(nplot**2):\n",
    "        \n",
    "        # Indices\n",
    "        i = idx//nplot; j = idx%nplot\n",
    "\n",
    "        # Remove axis\n",
    "        axes[i,j].axis('off')\n",
    "\n",
    "        # Rescale RGB channels by dividing my maximal value\n",
    "        if rescale:\n",
    "            scaled_img = np.copy(imgs[:,:,:,idx])\n",
    "            scaled_img[:,:,:3] = scaled_img[:,:,:3]/np.max(scaled_img[:,:,:3])\n",
    "            axes[i,j].imshow(scaled_img)\n",
    "        else:\n",
    "            axes[i,j].imshow(imgs[:,:,:,idx])\n",
    "    \n",
    "    # Tight layout so images will appear closer together\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save if filename is given\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Return to old parameters\n",
    "    plt.rcParams['figure.figsize'] = oldparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of plotting 8 times 8 images stored in \"faces\" and saving the output to a file named \"punks.png\"\n",
    "plotimgs(faces, 8, filename=\"punks.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above images some common features are clearly possible to be seen, which is a good indication that the NMF-algorithm should be able to reduce the amount of data to store the images. We will now start applying the NMF-algorithm to verify our previous claims, and to see if the algorithm is able to decompose the images into image components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Split the images into opacity and rgb channels\n",
    "faces_opacity = faces[:,:,3,:]\n",
    "faces_rgb = faces[:,:,:3,:]\n",
    "shape = faces_rgb.shape\n",
    "\n",
    "# Clever reshape \"trick\". This is the matrix we will apply the NMF to\n",
    "faces_reshaped = faces_rgb.reshape(np.prod(shape)//N, N)\n",
    "faces_opacity.shape\n",
    "\n",
    "faces_mean = np.mean(faces, -1)\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(faces_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = 64\n",
    "\n",
    "W_k, H_k, diff = NMF(faces_reshaped, d)\n",
    "\n",
    "W_k_reshape = W_k.reshape(24,24,3, d)\n",
    "W_k_reshape[W_k_reshape>1] = 1 # får verdier som er større enn én, så gjør disse om til én\n",
    "\n",
    "plotimgs(W_k_reshape, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reconstruction = np.dot(W_k, H_k).reshape(24, 24, 3, 500)\n",
    "reconstruction[reconstruction > 1] = 1\n",
    "\n",
    "plotimgs(reconstruction, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_matrix = reconstruction - faces_rgb\n",
    "\n",
    "difference_matrix[difference_matrix > 1] = 1\n",
    "# difference_matrix[difference_matrix < 0] = 0\n",
    "difference_matrix = np.abs(difference_matrix)\n",
    "\n",
    "plotimgs(difference_matrix, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw that the difference between the initial matrix and the final reconstruction WH got smaller the closer to zero the closer $d$ was to the rank of the matrix. Here $d$ has another meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "print(f\"Faces_reshaped rank: {np.linalg.matrix_rank(faces_reshaped)}\")\n",
    "\n",
    "\n",
    "for d in (16, 32, 64):\n",
    "    W, H, diff = NMF(faces_reshaped, d)\n",
    "    ax.semilogy(diff, label=f\"d={d}\")\n",
    "\n",
    "ax.set_title(\"Faces reshaped, after NMF\", size=14)\n",
    "ax.set_xlabel(\"k\", size=12)\n",
    "ax.set_ylabel(r\"$||A-W_kH_k||$\", size=12)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 16\n",
    "\n",
    "W_k, H_k, diff = NMF(faces_reshaped, d)\n",
    "\n",
    "W_k_reshape = W_k.reshape(24,24,3, d)\n",
    "W_k_reshape[W_k_reshape>1] = 1 # får verdier som er større enn én, så gjør disse om til én\n",
    "\n",
    "plotimgs(W_k_reshape, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For different values of $d$, we can clearly see that the Frobenius Norm converges for every instance. But the value that it converges to is smaller the bigger $d$. This is just as expected, since larger $d$ leads to more data getting stored in the new matrices. For example can the representation with $d=64$ possibly store all the colors of pixels of a hat where the representation for $d=16$ only stores the general shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this same behavior as before, it could be interesting to find out if there is a point where $\\lVert A-WH \\rvert$ dont get any smaller. At this point we would not need bigger $d$ to represent the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = np.zeros(11)\n",
    "diff_mean = np.zeros_like(differences)\n",
    "d_vals = np.zeros(11)\n",
    "values = [8, 16, 24, 32, 64, 96 , 128, 192, 256, 384, 512]\n",
    "for count, d in enumerate(values):\n",
    "    W, H, diff = NMF(faces_reshaped, d)\n",
    "    differences[count] = diff[-1]\n",
    "    diff_mean[count] = np.mean(diff)\n",
    "    d_vals[count] = d\n",
    "    print(f'{d} : {diff[-1]}')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "ax1.plot(d_vals, differences)\n",
    "ax1.set_xlabel('d', size=12)\n",
    "ax1.set_ylabel(r'$||A - WH ||_{F}$', size=12)\n",
    "\n",
    "ax2.plot(d_vals, differences/diff_mean)\n",
    "ax2.set_xlabel('d', size=12)\n",
    "ax2.set_ylabel(\"R\", size=12)\n",
    "ax2.text(300, 0.9, r'$R=\\frac{||A-W_NH_N||_F}{\\frac{1}{N} \\sum_{k=1}^{N} || A - W_kH_k ||_{F}}$', size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot show that the function is strictly descending, but almost converges at the end. Her vet jeg ikke helt hva man skal kommentere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduksjon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have worked with the images in sterile noiseless enviroment, which is not often true in real world problems. Noise is unwanted modifactions of signal, which is commonly found in most signal processing and indeed also images. There are a variety of different reasons why noise occurs, but most physical noise behaves similarly to Gaussian distributions, and can be assumed to be independent of the original image. Therefore we wil model noise as additive Gaussian noise given by $$A_{Noisy} = A + \\sigma E$$, where $\\sigma>0$ is a scalar noise level and E is a matrix with the same shape as A, with all components assumed to be given the standard normal distribution. \n",
    "\n",
    "Simarily to previous discussion we are assuming that the opacity channel is known, and therefore assuming only the RGB channels to be noisy. In addition we will only be assuming there to be noise on non-zero pixels, and we will be clipping the values to lie between 0 and 1. This is to keep the images plottable.\n",
    "\n",
    "With noise being defined for this discussion, one of the true strenghts of NMF can be highlighted. Namely it's abillity to denoise. If we interpret every column of W to be a mean of many noisy images with the same feature one would expect the variance generated by the noise to be reduction in variance, and therefore a reduction in noise. One could argue noise itself to be a feature and therefore the algorithm would be prone to having eigenvectors dedicated to recreating it. The differnce between noise and a true feature is that noise is random and without structure, and will therefore be harder to generalize and model for a wide array of images. This leads to a critical discussion into what value of d to choose. With lower values of d the model will learn little of the noise, with the cost of the reconstruction being poorer, which is known as underfitting. One the other hand if we choose a larger value of the, the algorithm will be able to learn more of the noise, but with image being recreated more faithfully, which is known as overfitting. The rest of the rapport will be focused discussing what values of d will lead to a balance between under- and overfitting, i.e. trying to find a best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(imgs_reshaped, sigma = 0.1):\n",
    "    \"\"\"\n",
    "    Adds gaussian noise to images as described in text.\n",
    "    Note that imgs must be given as a (24*24*3, N) numpy array, i.e the reshaped images\n",
    "    Input:\n",
    "        imgs_reshaped: (1728,N) numpy array\n",
    "        sigma: scalar, noise level\n",
    "    Output:\n",
    "        noisy_faces: (1728,N) numpy array containing noisy images\n",
    "    \"\"\"\n",
    "\n",
    "    # Array that will store the rgb channels of the noisy images\n",
    "    noisy_faces = np.copy(imgs_reshaped)\n",
    "\n",
    "    # Number of noisy values we need\n",
    "    nnzero = faces_reshaped[np.nonzero(imgs_reshaped)].shape[0]\n",
    "\n",
    "    # Sample noisy values and add noise\n",
    "    noise = np.random.normal(0.0,1,nnzero)\n",
    "    noisy_faces[np.nonzero(imgs_reshaped)] += sigma*noise\n",
    "\n",
    "    # Clip to lie between 0 and 1 so that we can still interpret them as images\n",
    "    noisy_faces = np.maximum(0.0,np.minimum(1.0, noisy_faces))\n",
    "\n",
    "    return noisy_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_faces = add_noise(faces_reshaped, sigma = 0.2)\n",
    "\n",
    "# Calculate the error of the noisy images\n",
    "noise_residual = np.linalg.norm(noisy_faces - faces_reshaped)\n",
    "print(noise_residual)\n",
    "\n",
    "# For plotting noisy images we add the opacity\n",
    "noisy_faces_with_opacity = np.zeros(faces.shape)\n",
    "noisy_faces_with_opacity[:,:,:3,:] = noisy_faces.reshape(faces_rgb.shape)\n",
    "noisy_faces_with_opacity[:,:,3,:] = faces_opacity\n",
    "plotimgs(noisy_faces_with_opacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 64\n",
    "\n",
    "W_k_Noisy, H_k_Noisy, diff = NMF(noisy_faces, d)\n",
    "\n",
    "W_k_reshape = W_k_Noisy.reshape(24,24,3, d)\n",
    "W_k_reshape[W_k_reshape>1] = 1 # får verdier som er større enn én, så gjør disse om til én\n",
    "\n",
    "plotimgs(W_k_reshape, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction1 = np.dot(W_k_Noisy, H_k_Noisy).reshape(24, 24, 3, 500)\n",
    "reconstruction1[reconstruction1 > 1] = 1\n",
    "\n",
    "plotimgs(reconstruction1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "HL = 23\n",
    "\n",
    "axes[0].imshow(faces[:,:,:, HL])\n",
    "axes[1].imshow(noisy_faces_with_opacity[:,:,:,HL])\n",
    "axes[2].imshow(reconstruction1[:,:,:, HL])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "d_values = [8, 16, 24, 32, 64, 96, 128, 192, 256, 384, 512]\n",
    "HL_face = np.zeros((24, 24, 3, len(d_values)))\n",
    "error = np.zeros_like(d_values)\n",
    "\n",
    "for i, d in enumerate(d_values):\n",
    "    W, H, diff = NMF(noisy_faces, d)\n",
    "    rec = (W @ H).reshape(24,24,3,500)\n",
    "    rec[rec > 1] = 1\n",
    "    HL_face[:,:,:,i] = rec[:,:,:,HL]\n",
    "    error[i] = np.linalg.norm(faces_reshaped - W @ H)\n",
    "    print(f'{d} : {error[i]:.3e}')\n",
    "    \n",
    "ax.plot(d_values, error)\n",
    "ax.set_title(\"Faces reshaped, after NMF\", size=14)\n",
    "ax.set_xlabel(\"d\", size=12)\n",
    "ax.set_ylabel(r\"$||A-WH||_F$\", size=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "ax.plot(d_values, error, label=\"with noice\")\n",
    "ax.plot(d_vals, differences, label=\"without noice\")\n",
    "ax.set_title(\"Faces reshaped, after NMF\", size=14)\n",
    "ax.set_xlabel(\"d\", size=12)\n",
    "ax.set_ylabel(r\"$||A-WH||_F$\", size=12)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the Frobenius norm from the noisy matrix is compared to the norm from matrix without noice, they follow each other closely from 0 to 50, but then the one with noice starts to flat out, while the other contiunes to descend. Noisy matrix looks to have its lowest value around $d=200$, after this the Norm actually gets bigger again, and dont fit to the conclusion that biggger $d$ is better that we got from earlier. The reason it increases is because from this point it starts picking up the noice in the attributes, not only the attributes itself as described earlier. This is called overfitting since the algortihm picks up diffences between the attributes, for example the bandana, which actually is not supposed to be there. On the other side of this problem is underfitting, which dont have the datapower to store all the attributes seperatly, but instead in some sort of mix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "\n",
    "W_k_Noisy, H_k_Noisy, diff = NMF(noisy_faces, d)\n",
    "\n",
    "W_k_reshape = W_k_Noisy.reshape(24,24,3, d)\n",
    "W_k_reshape[W_k_reshape>1] = 1 # får verdier som er større enn én, så gjør disse om til én\n",
    "\n",
    "\n",
    "reconstruction2 = np.dot(W_k_Noisy, H_k_Noisy).reshape(24, 24, 3, 500)\n",
    "reconstruction2[reconstruction2 > 1] = 1\n",
    "\n",
    "plotimgs(reconstruction2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(faces[:,:,:, 23])\n",
    "axes[1].imshow(reconstruction1[:,:,:, 23])\n",
    "axes[2].imshow(reconstruction2[:,:,:, 23])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, 23), ylim=(23, 0))\n",
    "data = HL_face\n",
    "blank = np.zeros_like(data[:,:,:,0])\n",
    "im = ax.imshow(blank)\n",
    "txt = ax.text(11, -1,\"\", size=14)\n",
    "\n",
    "def init():\n",
    "    im.set_data(blank)\n",
    "    txt.set_text(\"\")\n",
    "    return [im]\n",
    "def animate(i):\n",
    "    im.set_data(data[:,:,:,i])\n",
    "    txt.set_text(f\"d={i}\")\n",
    "    return [im]\n",
    "\n",
    "ani = FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=data.shape[-1], interval=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
